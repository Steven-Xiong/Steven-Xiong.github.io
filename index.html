<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Zhexiao Xiong</title>
  
  <meta name="author" content="Zhexiao Xiong">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Zhexiao Xiong</name>
              </p>
              <p>I am a second year Ph.D. student in Computer Science at <a href="https://cse.wustl.edu/">Washington University in St. Louis</a>. advised by Prof. <a href="https://jacobsn.github.io/">Nathan Jacobs</a> 
                Before that, I received my bachelor's degree from <a href="http://www.tju.edu.cn/english/index.htm">Tianjin University</a>.
              </p>
              <!-- <p>
              My research lies broadly in novel view synthesis, stereo matching, depth estimation and domain adaptation.
              </p> -->
              <p style="text-align:center">
                <a href="mailto:x.zhexiao@wustl.edu">Email</a> &nbsp/&nbsp
                <a href="data/Zhexiao_Xiong_Resume.pdf">CV</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <a href="https://scholar.google.com/citations?hl=zh-CN&user=OQGjvAQAAAAJ">Google Scholar</a> &nbsp/&nbsp
                <!-- <a href="https://twitter.com/jon_barron">Twitter</a> &nbsp/&nbsp -->
                <a href="https://www.linkedin.com/in/zhexiao-xiong-1446741b3/">Linkedin</a> &nbsp/&nbsp
                <a href="https://github.com/Steven-Xiong">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/JonBarron.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/JonBarron_circle.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                My research lies broadly in novel view synthesis, stereo matching, depth estimation and domain adaptation.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
				
    
    <tr onmouseout="zipnerf_stop()" onmouseover="zipnerf_start()"  bgcolor="#ffffd0">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='zipnerf_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/zipnerf.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/zipnerf.jpg' width="160">
        </div>
        <script type="text/javascript">
          function zipnerf_start() {
            document.getElementById('zipnerf_image').style.opacity = "1";
          }

          function zipnerf_stop() {
            document.getElementById('zipnerf_image').style.opacity = "0";
          }
          zipnerf_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="http://jonbarron.info/zipnerf">
          <papertitle>Zip-NeRF: Anti-Aliased Grid-Based Neural Radiance Fields</papertitle>
        </a>
        <br>
        <strong>Jonathan T. Barron</strong>,
        <a href="https://Steven-Xiong.github.io/">Ben Mildenhall</a>,
        <a href="https://scholar.harvard.edu/dorverbin/home">Dor Verbin</a>,
        <a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>,
        <a href="https://phogzone.com/">Peter Hedman</a>
        <br>
        <em>arXiv</em>, 2023
        <br>
        <a href="http://jonbarron.info/zipnerf">project page</a>
        /
        <a href="https://www.youtube.com/watch?v=xrrhynRzC8k">video</a>
        /
        <a href="https://arxiv.org/abs/2304.06706">arXiv</a>
        <p></p>
        <p>
        Combining mip-NeRF 360 and grid-based models like Instant NGP lets us reduce error rates by 8%&ndash;76% and accelerate training by 22x.
        </p>
      </td>
    </tr>
    
		
    <tr onmouseout="db3d_stop()" onmouseover="db3d_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='db3d_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/owl.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/owl.png' width="160">
        </div>
        <script type="text/javascript">
          function db3d_start() {
            document.getElementById('db3d_image').style.opacity = "1";
          }

          function db3d_stop() {
            document.getElementById('db3d_image').style.opacity = "0";
          }
          db3d_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
				<a href="https://dreambooth3d.github.io/">
          <papertitle>DreamBooth3D: Subject-Driven Text-to-3D Generation</papertitle>
        </a>
        <br>
        
<a href="https://amitraj93.github.io/">Amit Raj</a>, <a href="https://www.linkedin.com/in/zhexiao-xiong-1446741b3/">Srinivas Kaza</a>, <a href="https://poolio.github.io/">Ben Poole</a>, <a href="https://m-niemeyer.github.io/">Michael Niemeyer</a>, <a href="https://natanielruiz.github.io/">Nataniel Ruiz</a>, 
<a href="https://bmild.github.io/">Ben Mildenhall</a>, <a href="https://scholar.google.com/citations?hl=zh-CN&user=OQGjvAQAAAAJ">Shiran Zada</a>, <a href="https://kfiraberman.github.io/">Kfir Aberman</a>, <a href="http://people.csail.mit.edu/mrub/">Michael Rubinstein</a>, 
         <strong>Jonathan T. Barron</strong>, <a href="http://people.csail.mit.edu/yzli/">Yuanzhen Li</a>, <a href="https://varunjampani.github.io/">Varun Jampani</a>
        <br>
        <em>arXiv</em>, 2023
        <br>
				<a href="https://dreambooth3d.github.io/">project page</a> / 
				<a href="https://arxiv.org/abs/2303.13508">arXiv</a>
        <p></p>
        <p>Combining DreamBooth (personalized text-to-image) and DreamFusion (text-to-3D) yields high-quality, subject-specific 3D assets with text-driven modifications</p>
      </td>
    </tr>

    

    

	
  <tr onmouseout="ddp_stop()" onmouseover="ddp_start()">
    <td style="padding:20px;width:25%;vertical-align:middle">
      <div class="one">
        <div class="two" id='ddp_image'>
          <img src='images/ddp_after.jpg' width="160"></div>
        <img src='images/ddp_before.jpg' width="160">
      </div>
      <script type="text/javascript">
        function ddp_start() {
          document.getElementById('ddp_image').style.opacity = "1";
        }

        function ddp_stop() {
          document.getElementById('ddp_image').style.opacity = "0";
        }
        ddp_stop()
      </script>
    </td>
    <td style="padding:20px;width:75%;vertical-align:middle">
      <a href="https://arxiv.org/abs/2112.03288">
        <papertitle>Dense Depth Priors for Neural Radiance Fields from Sparse Input Views</papertitle>
      </a>
      <br>
			<a href="https://niessnerlab.org/members/barbara_roessle/profile.html">Barbara Roessle</a>,
			<strong>Jonathan T. Barron</strong>,
			<a href="https://bmild.github.io/">Ben Mildenhall</a>, 
			<a href="https://pratulsrinivasan.github.io/">Pratul Srinivasan</a>, 
			<a href="https://www.niessnerlab.org/">Matthias Nie√üner</a>
      <br>
			<em>CVPR</em>, 2022
      <br>
      <a href="https://arxiv.org/abs/2112.03288">arXiv</a>
      /
      <a href="https://www.youtube.com/watch?v=zzkvvdcvksc">video</a>
      <p></p>
      <p>
      Dense depth completion techniques applied to freely-available sparse stereo data can improve NeRF reconstructions in low-data regimes.
      </p>
    </td>

          <tr onmouseout="c5_stop()" onmouseover="c5_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='c5_image'>
                  <img src='images/c5_after.jpg' width="160"></div>
                <img src='images/c5_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function c5_start() {
                  document.getElementById('c5_image').style.opacity = "1";
                }

                function c5_stop() {
                  document.getElementById('c5_image').style.opacity = "0";
                }
                c5_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://arxiv.org/abs/2011.11890">
                <papertitle>Cross-Camera Convolutional Color Constancy</papertitle>
              </a>
              <br>
              <a href="https://sites.google.com/corp/view/mafifi">Mahmoud Afifi</a>,
              <strong>Jonathan T. Barron</strong>,
              <a href="http://www.chloelegendre.com/">Chloe LeGendre</a>,
              <a href="https://research.google/people/105312/">Yun-Ta Tsai</a>,
              <a href="https://www.linkedin.com/in/fbleibel/">Francois Bleibel</a>
              <br>
							<em>ICCV</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <p></p>
              <p>
                With some extra (unlabeled) test-set images, you can build a hypernetwork that calibrates itself at test time to previously-unseen cameras.
              </p>
            </td>
          </tr> 


          

          <tr onmouseout="nerfw_stop()" onmouseover="nerfw_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='nerfw_image'><video  width=100% height=100% muted autoplay loop>
                <source src="images/nerfw_after.mp4" type="video/mp4">
                Your browser does not support the video tag.
                </video></div>
                <img src='images/nerfw_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function nerfw_start() {
                  document.getElementById('nerfw_image').style.opacity = "1";
                }

                function nerfw_stop() {
                  document.getElementById('nerfw_image').style.opacity = "0";
                }
                nerfw_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="https://nerf-w.github.io/">
                <papertitle>NeRF in the Wild: Neural Radiance Fields for Unconstrained Photo Collections</papertitle>
              </a>
              <br>
              <a href="http://www.ricardomartinbrualla.com/">Ricardo Martin-Brualla*</a>,
              <a href="https://scholar.google.com/citations?user=g98QcZUAAAAJ&hl=en">Noha Radwan*</a>,
              <a href="https://research.google/people/105804/">Mehdi S. M. Sajjadi*</a>, <br>
              <strong>Jonathan T. Barron</strong>,
              <a href="https://scholar.google.com/citations?user=FXNJRDoAAAAJ&hl=en">Alexey Dosovitskiy</a>,
              <a href="http://www.stronglyconvex.com/about.html">Daniel Duckworth</a>
              <br>
              <em>CVPR</em>, 2021 &nbsp <font color="red"><strong>(Oral Presentation)</strong></font>
              <br>
              <a href="https://nerf-w.github.io/">project page</a> /
              <a href="https://arxiv.org/abs/2008.02268">arXiv</a> /
              <a href="https://www.youtube.com/watch?v=mRAKVQj5LRA">video</a>
              <p></p>
              <p>Letting NeRF reason about occluders and appearance variation produces photorealistic view synthesis using only unstructured internet photos.</p>
            </td>
          </tr> 

          <tr onmouseout="dualrefl_stop()" onmouseover="dualrefl_start()">
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='dualrefl_image'>
                  <img src='images/dualrefl_after.jpg' width="160"></div>
                <img src='images/dualrefl_before.jpg' width="160">
              </div>
              <script type="text/javascript">
                function dualrefl_start() {
                  document.getElementById('dualrefl_image').style.opacity = "1";
                }

                function dualrefl_stop() {
                  document.getElementById('dualrefl_image').style.opacity = "0";
                }
                dualrefl_stop()
              </script>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
              <a href="http://sniklaus.com/dualref">
                <papertitle>StereoFlowGAN: Co-training for Stereo and Flow with Unsupervised Domain Adaptation</papertitle>
              </a>
              <br>
              <a href="http://sniklaus.com/welcome">Simon Niklaus</a>,
              <a href="https://people.eecs.berkeley.edu/~cecilia77/">Xuaner (Cecilia) Zhang</a>,
              <strong>Zhexiao Xiong</strong>, <br>
              <a href="http://nealwadhwa.com">Feng Qiao</a>,
              <a href="http://rahuldotgarg.appspot.com/">Yu Zhang</a>,
              <a href="http://web.cecs.pdx.edu/~fliu/">Nathan Jacobs</a>,
              <br>
              <em>BMVC</em>, 2023
              <br>
              <a href="http://sniklaus.com/dualref">project page</a> /
              <a href="https://arxiv.org/abs/2010.00702">arXiv</a>
              <p></p>
              <p>
                Reflections and the things behind them often exhibit parallax, and this lets you remove reflections from stereo pairs.
              </p>
            </td>
          </tr>

					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                Feel free to steal this website's <a href="https://github.com/jonbarron/jonbarron_website">source code</a>. <strong>Do not</strong> scrape the HTML from this page itself, as it includes analytics tags that you do not want on your own website &mdash; use the github code instead. Also, consider using <a href="https://leonidk.com/">Leonid Keselman</a>'s <a href="https://github.com/leonidk/new_website">Jekyll fork</a> of this page.
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
